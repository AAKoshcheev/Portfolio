{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разбиение-на-выборки\" data-toc-modified-id=\"Разбиение-на-выборки-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Разбиение на выборки</a></span></li><li><span><a href=\"#Выбор-наилучшей-модели-и-поиск-гиперпараметров-через-GridSearch\" data-toc-modified-id=\"Выбор-наилучшей-модели-и-поиск-гиперпараметров-через-GridSearch-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Выбор наилучшей модели и поиск гиперпараметров через GridSearch</a></span></li><li><span><a href=\"#Модель-CatBoost\" data-toc-modified-id=\"Модель-CatBoost-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Модель CatBoost</a></span></li><li><span><a href=\"#Модель-LightGBM\" data-toc-modified-id=\"Модель-LightGBM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Модель LightGBM</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## импорт библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import tensorflow\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import BertTokenizer\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from wordcloud import WordCloud\n",
    "from transformers import (AutoModel, AutoTokenizer, AutoConfig,\n",
    "                                  AutoModelForSequenceClassification, TrainingArguments, Trainer, logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 583 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127113</th>\n",
       "      <td>Well, I have to agree that whoever destroyed t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21330</th>\n",
       "      <td>\"\\n I forgot to mention how long! I will give ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44404</th>\n",
       "      <td>\"Hello , and welcome to Wikipedia! The first t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66733</th>\n",
       "      <td>\"\\n\\n More information about the moschee \\n\\nM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25350</th>\n",
       "      <td>\"\\n\\nFirst of all, where do you get the idea t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140039</th>\n",
       "      <td>] // 10\\n[http://www.webcitation.org/5oGeSq8ag 11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>I think Masem (whom I respect very highly) sum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43630</th>\n",
       "      <td>23:39, Oct 2, 2004 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79459</th>\n",
       "      <td>Phil Donahue\\n\\nI know he was at WDTN during h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14148</th>\n",
       "      <td>\"\\nYeagh; self-auditing.  This sort of demand ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "127113  Well, I have to agree that whoever destroyed t...      1\n",
       "21330   \"\\n I forgot to mention how long! I will give ...      0\n",
       "44404   \"Hello , and welcome to Wikipedia! The first t...      0\n",
       "66733   \"\\n\\n More information about the moschee \\n\\nM...      0\n",
       "25350   \"\\n\\nFirst of all, where do you get the idea t...      0\n",
       "140039  ] // 10\\n[http://www.webcitation.org/5oGeSq8ag 11      0\n",
       "16995   I think Masem (whom I respect very highly) sum...      0\n",
       "43630                            23:39, Oct 2, 2004 (UTC)      0\n",
       "79459   Phil Donahue\\n\\nI know he was at WDTN during h...      0\n",
       "14148   \"\\nYeagh; self-auditing.  This sort of demand ...      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# импорт данных и первый их анализ\n",
    "data = pd.read_csv(r\"D:\\toxic_comments.csv\", index_col=0)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#получение общей информации о датасете\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159292.000000\n",
       "mean        0.101612\n",
       "std         0.302139\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#описание данных\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно говорить о дисбалансе классов. Около 10% токсичных комментариев, 90% не токсичны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.94 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#загрузка модели и токенизатора BERT\n",
    "model = AutoModel.from_pretrained(\"unitary/toxic-bert\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 44.1 s\n",
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#проводим первичную токенизацию для текста\n",
    "pre_tokenized = data['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим из сообщения, имеем ограничение в 512 токенов в строке. Необходимо убрать строки с превышением лимита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 7526, 2339, 1996, 10086, 2015, 2081, 210...</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 1040, 1005, 22091, 2860, 999, 2002, 3503...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  len\n",
       "0  [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...      0   68\n",
       "1  [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...      0   35\n",
       "2  [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...      0   54\n",
       "3  [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...      0  144\n",
       "4  [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...      0   21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаем ограничение\n",
    "data_temp = pd.DataFrame(pre_tokenized)\n",
    "data_temp['toxic'] = data['toxic']\n",
    "len_list = []\n",
    "for i in data_temp['text']:\n",
    "    len_list.append(len(i))\n",
    "data_temp['len'] = len_list\n",
    "data_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляем строки с превышающими лимит токенами\n",
    "data_temp = data_temp.loc[data_temp['len'] < 513].drop(['len'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#собираем датафрейм после фильтрации\n",
    "data_left = data['text']\n",
    "data_right = data_temp['toxic']\n",
    "data_final = pd.concat([data_left, data_right], axis=1, join=\"inner\")\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155634, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#для получения embedding для всего датасета потребуются большие вычислительные мощности, поэтому процедуру их расчета представил на выборке в 311 \n",
    "out, data_final = train_test_split(data_final, test_size=0.999, #с соотношением \n",
    "    random_state=12345, #с заданной опорой для рандома \n",
    "    stratify= data_final['toxic']) #с заданной стратификацией по целевому признаку\n",
    "data_final = data_final.reset_index(drop=True)\n",
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\n\\nI believe he archived the discussion beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bot error \\n\\nOrphanBot applied an incorrect t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Truce\\n\\nI call a truce.  But I didn't see thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's unfortunate that the sources are vague on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it staying and no buts about it\\n\\ni wll keep ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  \"\\n\\nI believe he archived the discussion beca...      0\n",
       "1  Bot error \\n\\nOrphanBot applied an incorrect t...      0\n",
       "2  Truce\\n\\nI call a truce.  But I didn't see thi...      0\n",
       "3  It's unfortunate that the sources are vague on...      0\n",
       "4  it staying and no buts about it\\n\\ni wll keep ...      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.83 %\n"
     ]
    }
   ],
   "source": [
    "#проверяем баланс классов\n",
    "print(round((data_final['toxic'].count() - data_final['toxic'].sum()) / data_final['toxic'].count() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Баланс классов соблюдается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39.4 s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#проводим токенизацию\n",
    "tokenized = data_final['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверяем длину токенов\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#паддинг и маска\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16465e86d4404f15a77545c7f0ccc531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 59min 11s\n",
      "Wall time: 1h 43min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#создание эмбеддингов\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579122</td>\n",
       "      <td>-0.976771</td>\n",
       "      <td>0.526930</td>\n",
       "      <td>-0.344545</td>\n",
       "      <td>1.073406</td>\n",
       "      <td>0.116593</td>\n",
       "      <td>-0.191745</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>-0.462766</td>\n",
       "      <td>-0.718300</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.112387</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>-0.709351</td>\n",
       "      <td>0.126624</td>\n",
       "      <td>0.879271</td>\n",
       "      <td>-0.525642</td>\n",
       "      <td>-0.726852</td>\n",
       "      <td>0.379305</td>\n",
       "      <td>0.087888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.657009</td>\n",
       "      <td>-1.018494</td>\n",
       "      <td>0.449042</td>\n",
       "      <td>-0.272752</td>\n",
       "      <td>0.991285</td>\n",
       "      <td>0.317469</td>\n",
       "      <td>-0.043647</td>\n",
       "      <td>0.013462</td>\n",
       "      <td>-0.390273</td>\n",
       "      <td>-0.622839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.212102</td>\n",
       "      <td>0.227788</td>\n",
       "      <td>-0.635808</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.852536</td>\n",
       "      <td>-0.453627</td>\n",
       "      <td>-0.715883</td>\n",
       "      <td>0.316769</td>\n",
       "      <td>0.284531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.754768</td>\n",
       "      <td>-0.931944</td>\n",
       "      <td>0.428935</td>\n",
       "      <td>-0.719045</td>\n",
       "      <td>0.914379</td>\n",
       "      <td>0.537290</td>\n",
       "      <td>0.065258</td>\n",
       "      <td>-0.194789</td>\n",
       "      <td>-0.445472</td>\n",
       "      <td>-0.878202</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.210364</td>\n",
       "      <td>0.502389</td>\n",
       "      <td>-0.651083</td>\n",
       "      <td>0.111464</td>\n",
       "      <td>0.670703</td>\n",
       "      <td>-0.544642</td>\n",
       "      <td>-0.625255</td>\n",
       "      <td>0.514120</td>\n",
       "      <td>-0.026531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.638190</td>\n",
       "      <td>-0.966847</td>\n",
       "      <td>0.419287</td>\n",
       "      <td>-0.533452</td>\n",
       "      <td>0.997320</td>\n",
       "      <td>0.215355</td>\n",
       "      <td>-0.146769</td>\n",
       "      <td>0.056217</td>\n",
       "      <td>-0.409464</td>\n",
       "      <td>-0.591199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233097</td>\n",
       "      <td>0.209634</td>\n",
       "      <td>-0.693372</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.884811</td>\n",
       "      <td>-0.568885</td>\n",
       "      <td>-0.804295</td>\n",
       "      <td>0.446663</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.427659</td>\n",
       "      <td>-0.665191</td>\n",
       "      <td>0.925915</td>\n",
       "      <td>-0.578008</td>\n",
       "      <td>0.789994</td>\n",
       "      <td>0.310947</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>-0.182835</td>\n",
       "      <td>-0.503202</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.040302</td>\n",
       "      <td>0.513854</td>\n",
       "      <td>-0.360468</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>-0.459235</td>\n",
       "      <td>-0.981930</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.314995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155595</th>\n",
       "      <td>-0.758716</td>\n",
       "      <td>-0.910621</td>\n",
       "      <td>0.399189</td>\n",
       "      <td>-0.492608</td>\n",
       "      <td>0.946495</td>\n",
       "      <td>0.246570</td>\n",
       "      <td>-0.092683</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>-0.560727</td>\n",
       "      <td>-0.747882</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.275620</td>\n",
       "      <td>0.291381</td>\n",
       "      <td>-0.676891</td>\n",
       "      <td>0.438761</td>\n",
       "      <td>0.945436</td>\n",
       "      <td>-0.589925</td>\n",
       "      <td>-0.865059</td>\n",
       "      <td>0.281674</td>\n",
       "      <td>0.140597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155596</th>\n",
       "      <td>-0.717656</td>\n",
       "      <td>-0.941628</td>\n",
       "      <td>0.397711</td>\n",
       "      <td>-0.228470</td>\n",
       "      <td>1.182325</td>\n",
       "      <td>0.274734</td>\n",
       "      <td>0.326376</td>\n",
       "      <td>0.139614</td>\n",
       "      <td>-0.160068</td>\n",
       "      <td>-0.297057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617464</td>\n",
       "      <td>0.499630</td>\n",
       "      <td>-0.541272</td>\n",
       "      <td>-0.495913</td>\n",
       "      <td>0.408830</td>\n",
       "      <td>-0.475904</td>\n",
       "      <td>-0.771808</td>\n",
       "      <td>0.697678</td>\n",
       "      <td>0.467036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155597</th>\n",
       "      <td>-0.701214</td>\n",
       "      <td>-0.901648</td>\n",
       "      <td>0.792093</td>\n",
       "      <td>-0.387406</td>\n",
       "      <td>1.077377</td>\n",
       "      <td>0.299192</td>\n",
       "      <td>-0.080067</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>-0.431653</td>\n",
       "      <td>-0.699643</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.285836</td>\n",
       "      <td>0.286392</td>\n",
       "      <td>-0.677304</td>\n",
       "      <td>0.148410</td>\n",
       "      <td>0.758705</td>\n",
       "      <td>-0.524568</td>\n",
       "      <td>-0.678514</td>\n",
       "      <td>0.331908</td>\n",
       "      <td>0.126121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155598</th>\n",
       "      <td>-0.589732</td>\n",
       "      <td>-0.943831</td>\n",
       "      <td>0.565660</td>\n",
       "      <td>-0.325469</td>\n",
       "      <td>1.039689</td>\n",
       "      <td>0.185136</td>\n",
       "      <td>-0.104915</td>\n",
       "      <td>0.097853</td>\n",
       "      <td>-0.356026</td>\n",
       "      <td>-0.691238</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.184709</td>\n",
       "      <td>0.097172</td>\n",
       "      <td>-0.826426</td>\n",
       "      <td>0.114271</td>\n",
       "      <td>0.928049</td>\n",
       "      <td>-0.575514</td>\n",
       "      <td>-0.806420</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155599</th>\n",
       "      <td>-0.652020</td>\n",
       "      <td>-0.994479</td>\n",
       "      <td>0.578934</td>\n",
       "      <td>-0.467285</td>\n",
       "      <td>0.883873</td>\n",
       "      <td>0.195933</td>\n",
       "      <td>-0.168802</td>\n",
       "      <td>0.172148</td>\n",
       "      <td>-0.390117</td>\n",
       "      <td>-0.653780</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.307963</td>\n",
       "      <td>0.139307</td>\n",
       "      <td>-0.756430</td>\n",
       "      <td>0.236997</td>\n",
       "      <td>0.922894</td>\n",
       "      <td>-0.500279</td>\n",
       "      <td>-0.739869</td>\n",
       "      <td>0.314211</td>\n",
       "      <td>0.200351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155600 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.579122 -0.976771  0.526930 -0.344545  1.073406  0.116593 -0.191745   \n",
       "1      -0.657009 -1.018494  0.449042 -0.272752  0.991285  0.317469 -0.043647   \n",
       "2      -0.754768 -0.931944  0.428935 -0.719045  0.914379  0.537290  0.065258   \n",
       "3      -0.638190 -0.966847  0.419287 -0.533452  0.997320  0.215355 -0.146769   \n",
       "4      -0.427659 -0.665191  0.925915 -0.578008  0.789994  0.310947  0.231700   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "155595 -0.758716 -0.910621  0.399189 -0.492608  0.946495  0.246570 -0.092683   \n",
       "155596 -0.717656 -0.941628  0.397711 -0.228470  1.182325  0.274734  0.326376   \n",
       "155597 -0.701214 -0.901648  0.792093 -0.387406  1.077377  0.299192 -0.080067   \n",
       "155598 -0.589732 -0.943831  0.565660 -0.325469  1.039689  0.185136 -0.104915   \n",
       "155599 -0.652020 -0.994479  0.578934 -0.467285  0.883873  0.195933 -0.168802   \n",
       "\n",
       "               7         8         9  ...       759       760       761  \\\n",
       "0       0.019543 -0.462766 -0.718300  ... -1.112387  0.175781 -0.709351   \n",
       "1       0.013462 -0.390273 -0.622839  ... -1.212102  0.227788 -0.635808   \n",
       "2      -0.194789 -0.445472 -0.878202  ... -1.210364  0.502389 -0.651083   \n",
       "3       0.056217 -0.409464 -0.591199  ... -1.233097  0.209634 -0.693372   \n",
       "4       0.144695 -0.182835 -0.503202  ... -1.040302  0.513854 -0.360468   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "155595  0.047783 -0.560727 -0.747882  ... -1.275620  0.291381 -0.676891   \n",
       "155596  0.139614 -0.160068 -0.297057  ... -0.617464  0.499630 -0.541272   \n",
       "155597  0.024048 -0.431653 -0.699643  ... -1.285836  0.286392 -0.677304   \n",
       "155598  0.097853 -0.356026 -0.691238  ... -1.184709  0.097172 -0.826426   \n",
       "155599  0.172148 -0.390117 -0.653780  ... -1.307963  0.139307 -0.756430   \n",
       "\n",
       "             762       763       764       765       766       767  toxic  \n",
       "0       0.126624  0.879271 -0.525642 -0.726852  0.379305  0.087888      0  \n",
       "1       0.140072  0.852536 -0.453627 -0.715883  0.316769  0.284531      0  \n",
       "2       0.111464  0.670703 -0.544642 -0.625255  0.514120 -0.026531      0  \n",
       "3       0.049386  0.884811 -0.568885 -0.804295  0.446663  0.035812      0  \n",
       "4       0.196113  0.722595 -0.459235 -0.981930  0.709400  0.314995      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "155595  0.438761  0.945436 -0.589925 -0.865059  0.281674  0.140597      0  \n",
       "155596 -0.495913  0.408830 -0.475904 -0.771808  0.697678  0.467036      0  \n",
       "155597  0.148410  0.758705 -0.524568 -0.678514  0.331908  0.126121      0  \n",
       "155598  0.114271  0.928049 -0.575514 -0.806420  0.302182  0.042963      0  \n",
       "155599  0.236997  0.922894 -0.500279 -0.739869  0.314211  0.200351      0  \n",
       "\n",
       "[155600 rows x 769 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создание датасета с эмбеддингами и таргетом\n",
    "data_ed = pd.DataFrame(np.concatenate(embeddings)) \n",
    "data_ed['toxic'] = data_final['toxic']\n",
    "data_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохранение эмбеддингов в файл\n",
    "data_ed.to_csv(r'D:\\toxic_bert_full_toxic_data_ed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.579122</th>\n",
       "      <td>-0.976771</td>\n",
       "      <td>0.526930</td>\n",
       "      <td>-0.344545</td>\n",
       "      <td>1.073406</td>\n",
       "      <td>0.116593</td>\n",
       "      <td>-0.191745</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>-0.462765</td>\n",
       "      <td>-0.718299</td>\n",
       "      <td>-0.240531</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.112387</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>-0.709351</td>\n",
       "      <td>0.126624</td>\n",
       "      <td>0.879271</td>\n",
       "      <td>-0.525642</td>\n",
       "      <td>-0.726853</td>\n",
       "      <td>0.379305</td>\n",
       "      <td>0.087888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.657009</th>\n",
       "      <td>-1.018494</td>\n",
       "      <td>0.449042</td>\n",
       "      <td>-0.272752</td>\n",
       "      <td>0.991285</td>\n",
       "      <td>0.317469</td>\n",
       "      <td>-0.043647</td>\n",
       "      <td>0.013462</td>\n",
       "      <td>-0.390273</td>\n",
       "      <td>-0.622839</td>\n",
       "      <td>-0.202760</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.212102</td>\n",
       "      <td>0.227788</td>\n",
       "      <td>-0.635808</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.852536</td>\n",
       "      <td>-0.453627</td>\n",
       "      <td>-0.715883</td>\n",
       "      <td>0.316769</td>\n",
       "      <td>0.284531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.754768</th>\n",
       "      <td>-0.931944</td>\n",
       "      <td>0.428935</td>\n",
       "      <td>-0.719045</td>\n",
       "      <td>0.914380</td>\n",
       "      <td>0.537290</td>\n",
       "      <td>0.065258</td>\n",
       "      <td>-0.194789</td>\n",
       "      <td>-0.445472</td>\n",
       "      <td>-0.878202</td>\n",
       "      <td>-0.072412</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.210364</td>\n",
       "      <td>0.502389</td>\n",
       "      <td>-0.651083</td>\n",
       "      <td>0.111464</td>\n",
       "      <td>0.670703</td>\n",
       "      <td>-0.544642</td>\n",
       "      <td>-0.625255</td>\n",
       "      <td>0.514120</td>\n",
       "      <td>-0.026531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.638190</th>\n",
       "      <td>-0.966847</td>\n",
       "      <td>0.419287</td>\n",
       "      <td>-0.533452</td>\n",
       "      <td>0.997320</td>\n",
       "      <td>0.215355</td>\n",
       "      <td>-0.146769</td>\n",
       "      <td>0.056217</td>\n",
       "      <td>-0.409464</td>\n",
       "      <td>-0.591199</td>\n",
       "      <td>-0.214927</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233097</td>\n",
       "      <td>0.209634</td>\n",
       "      <td>-0.693372</td>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.884811</td>\n",
       "      <td>-0.568885</td>\n",
       "      <td>-0.804295</td>\n",
       "      <td>0.446663</td>\n",
       "      <td>0.035812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.427659</th>\n",
       "      <td>-0.665191</td>\n",
       "      <td>0.925914</td>\n",
       "      <td>-0.578008</td>\n",
       "      <td>0.789994</td>\n",
       "      <td>0.310947</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>-0.182835</td>\n",
       "      <td>-0.503202</td>\n",
       "      <td>-0.042319</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.040302</td>\n",
       "      <td>0.513854</td>\n",
       "      <td>-0.360468</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>-0.459235</td>\n",
       "      <td>-0.981930</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.314995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4         5         6  \\\n",
       "0                                                                       \n",
       "-0.579122 -0.976771  0.526930 -0.344545  1.073406  0.116593 -0.191745   \n",
       "-0.657009 -1.018494  0.449042 -0.272752  0.991285  0.317469 -0.043647   \n",
       "-0.754768 -0.931944  0.428935 -0.719045  0.914380  0.537290  0.065258   \n",
       "-0.638190 -0.966847  0.419287 -0.533452  0.997320  0.215355 -0.146769   \n",
       "-0.427659 -0.665191  0.925914 -0.578008  0.789994  0.310947  0.231700   \n",
       "\n",
       "                  7         8         9        10  ...       759       760  \\\n",
       "0                                                  ...                       \n",
       "-0.579122  0.019543 -0.462765 -0.718299 -0.240531  ... -1.112387  0.175781   \n",
       "-0.657009  0.013462 -0.390273 -0.622839 -0.202760  ... -1.212102  0.227788   \n",
       "-0.754768 -0.194789 -0.445472 -0.878202 -0.072412  ... -1.210364  0.502389   \n",
       "-0.638190  0.056217 -0.409464 -0.591199 -0.214927  ... -1.233097  0.209634   \n",
       "-0.427659  0.144695 -0.182835 -0.503202 -0.042319  ... -1.040302  0.513854   \n",
       "\n",
       "                761       762       763       764       765       766  \\\n",
       "0                                                                       \n",
       "-0.579122 -0.709351  0.126624  0.879271 -0.525642 -0.726853  0.379305   \n",
       "-0.657009 -0.635808  0.140072  0.852536 -0.453627 -0.715883  0.316769   \n",
       "-0.754768 -0.651083  0.111464  0.670703 -0.544642 -0.625255  0.514120   \n",
       "-0.638190 -0.693372  0.049386  0.884811 -0.568885 -0.804295  0.446663   \n",
       "-0.427659 -0.360468  0.196113  0.722595 -0.459235 -0.981930  0.709400   \n",
       "\n",
       "                767  toxic  \n",
       "0                           \n",
       "-0.579122  0.087888      0  \n",
       "-0.657009  0.284531      0  \n",
       "-0.754768 -0.026531      0  \n",
       "-0.638190  0.035812      0  \n",
       "-0.427659  0.314995      0  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#загружаем ранее преобразованные эмбеддинги из файла\n",
    "data_embedded = pd.read_csv(r'D:\\toxic_bert_full_toxic_data_ed.csv', index_col=0)\n",
    "data_embedded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 155600 entries, -0.57912236 to -0.6520197\n",
      "Columns: 768 entries, 1 to toxic\n",
      "dtypes: float64(767), int64(1)\n",
      "memory usage: 912.9 MB\n"
     ]
    }
   ],
   "source": [
    "data_embedded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.83 %\n"
     ]
    }
   ],
   "source": [
    "#дисбаланс классов сохранен\n",
    "print(round((data_embedded['toxic'].count() - data_embedded['toxic'].sum()) / data_embedded['toxic'].count() * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split( #создаем 4 датасета, два признаков и два целевых, \n",
    "    data_embedded.drop(columns='toxic'), #для датасетов признаков удаляем целевой\n",
    "    data_embedded['toxic'], #для целевого оставляем только целевой\n",
    "    test_size=0.2, #с соотношением \n",
    "    random_state=12345, #с заданной опорой для рандома \n",
    "    stratify= data_embedded['toxic']) #с заданной стратификацией по целевому признаку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор наилучшей модели и поиск гиперпараметров через GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('model', LogisticRegression())])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#подбор модели через пайплайн\n",
    "pipeline = Pipeline([('model', LogisticRegression())])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создание перечня для перебора параметров\n",
    "estimators_range = [x for x in range(1, 30, 2)]\n",
    "max_depth_range = [x for x in range(20, 1000, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#формирование набора параметров\n",
    "params = [{\n",
    "        'model': [LogisticRegression(solver='liblinear', random_state=12345, class_weight= 'balanced')],\n",
    "        'model__max_iter': range (100, 1000, 100),\n",
    "        'model__C': np.arange(0.1, 1.0, 0.1),\n",
    "    },\n",
    "        \n",
    "    \n",
    "    {\n",
    "        'model': [RandomForestClassifier(class_weight= 'balanced', random_state=12345)],\n",
    "        'model__n_estimators': estimators_range,\n",
    "        'model__max_depth': max_depth_range,\n",
    "         },\n",
    "\n",
    "    {\n",
    "        'model': [DecisionTreeClassifier(class_weight= 'balanced', random_state=12345)],\n",
    "        'model__max_depth': max_depth_range,\n",
    "            }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#модель для RandomizedSearchCV\n",
    "grid = RandomizedSearchCV(pipeline,\n",
    "                    params,\n",
    "                    cv=5,\n",
    "                    verbose=1,\n",
    "                    random_state=12345,\n",
    "                    scoring='f1',\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "CPU times: total: 4min 28s\n",
      "Wall time: 43min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;model&#x27;, LogisticRegression())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;model&#x27;: [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                      random_state=12345,\n",
       "                                                                      solver=&#x27;liblinear&#x27;)],\n",
       "                                         &#x27;model__C&#x27;: array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                         &#x27;model__max_iter&#x27;: range(100, 1000, 100)},\n",
       "                                        {&#x27;model&#x27;: [RandomForestClassifier(class_weight=&#x27;b...\n",
       "                                                              520, 540, 560,\n",
       "                                                              580, 600, ...],\n",
       "                                         &#x27;model__n_estimators&#x27;: [1, 3, 5, 7, 9,\n",
       "                                                                 11, 13, 15, 17,\n",
       "                                                                 19, 21, 23, 25,\n",
       "                                                                 27, 29]},\n",
       "                                        {&#x27;model&#x27;: [DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                          random_state=12345)],\n",
       "                                         &#x27;model__max_depth&#x27;: [20, 40, 60, 80,\n",
       "                                                              100, 120, 140,\n",
       "                                                              160, 180, 200,\n",
       "                                                              220, 240, 260,\n",
       "                                                              280, 300, 320,\n",
       "                                                              340, 360, 380,\n",
       "                                                              400, 420, 440,\n",
       "                                                              460, 480, 500,\n",
       "                                                              520, 540, 560,\n",
       "                                                              580, 600, ...]}],\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;model&#x27;, LogisticRegression())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions=[{&#x27;model&#x27;: [LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                      random_state=12345,\n",
       "                                                                      solver=&#x27;liblinear&#x27;)],\n",
       "                                         &#x27;model__C&#x27;: array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                         &#x27;model__max_iter&#x27;: range(100, 1000, 100)},\n",
       "                                        {&#x27;model&#x27;: [RandomForestClassifier(class_weight=&#x27;b...\n",
       "                                                              520, 540, 560,\n",
       "                                                              580, 600, ...],\n",
       "                                         &#x27;model__n_estimators&#x27;: [1, 3, 5, 7, 9,\n",
       "                                                                 11, 13, 15, 17,\n",
       "                                                                 19, 21, 23, 25,\n",
       "                                                                 27, 29]},\n",
       "                                        {&#x27;model&#x27;: [DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                                          random_state=12345)],\n",
       "                                         &#x27;model__max_depth&#x27;: [20, 40, 60, 80,\n",
       "                                                              100, 120, 140,\n",
       "                                                              160, 180, 200,\n",
       "                                                              220, 240, 260,\n",
       "                                                              280, 300, 320,\n",
       "                                                              340, 360, 380,\n",
       "                                                              400, 420, 440,\n",
       "                                                              460, 480, 500,\n",
       "                                                              520, 540, 560,\n",
       "                                                              580, 600, ...]}],\n",
       "                   random_state=12345, scoring=&#x27;f1&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions=[{'model': [LogisticRegression(class_weight='balanced',\n",
       "                                                                      random_state=12345,\n",
       "                                                                      solver='liblinear')],\n",
       "                                         'model__C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                                         'model__max_iter': range(100, 1000, 100)},\n",
       "                                        {'model': [RandomForestClassifier(class_weight='b...\n",
       "                                                              520, 540, 560,\n",
       "                                                              580, 600, ...],\n",
       "                                         'model__n_estimators': [1, 3, 5, 7, 9,\n",
       "                                                                 11, 13, 15, 17,\n",
       "                                                                 19, 21, 23, 25,\n",
       "                                                                 27, 29]},\n",
       "                                        {'model': [DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                                          random_state=12345)],\n",
       "                                         'model__max_depth': [20, 40, 60, 80,\n",
       "                                                              100, 120, 140,\n",
       "                                                              160, 180, 200,\n",
       "                                                              220, 240, 260,\n",
       "                                                              280, 300, 320,\n",
       "                                                              340, 360, 380,\n",
       "                                                              400, 420, 440,\n",
       "                                                              460, 480, 500,\n",
       "                                                              520, 540, 560,\n",
       "                                                              580, 600, ...]}],\n",
       "                   random_state=12345, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#обучаем модель на тренировочных данных\n",
    "grid.fit(features_train, target_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 21,\n",
       " 'model__max_depth': 400,\n",
       " 'model': RandomForestClassifier(class_weight='balanced', max_depth=400, n_estimators=21,\n",
       "                        random_state=12345)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выводим параметры наилучшей модели\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392359185464443"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выводим лучший результат\n",
    "abs(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры у модели RandomForestClassifier(class_weight='balanced', max_depth=400, n_estimators=21,\n",
    "                        random_state=12345). Лучший результат f1=0.939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.9302775\ttotal: 459ms\tremaining: 22.5s\n",
      "5:\tlearn: 0.9487665\ttotal: 1.25s\tremaining: 9.2s\n",
      "10:\tlearn: 0.9533948\ttotal: 2.03s\tremaining: 7.21s\n",
      "15:\tlearn: 0.9566898\ttotal: 2.79s\tremaining: 5.92s\n",
      "20:\tlearn: 0.9607797\ttotal: 3.56s\tremaining: 4.92s\n",
      "25:\tlearn: 0.9636148\ttotal: 4.36s\tremaining: 4.02s\n",
      "30:\tlearn: 0.9661439\ttotal: 5.13s\tremaining: 3.14s\n",
      "35:\tlearn: 0.9686846\ttotal: 5.93s\tremaining: 2.31s\n",
      "40:\tlearn: 0.9713811\ttotal: 6.68s\tremaining: 1.47s\n",
      "45:\tlearn: 0.9728875\ttotal: 7.45s\tremaining: 648ms\n",
      "49:\tlearn: 0.9740162\ttotal: 8.04s\tremaining: 0us\n",
      "F1: {'learn': {'Logloss': 0.018272324882952277, 'F1': 0.9740162151473205}}\n",
      "CPU times: total: 1min 9s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Обучаем модель CatBoostRegressor\n",
    "cb = CatBoostClassifier(custom_metric='F1', eval_metric='F1', iterations=50)\n",
    "cb.fit(features_train, target_train.values, verbose=5)\n",
    "print(f'F1: {cb.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель CatBoost показывает лучший результат в 'F1': 0.974"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 12659, number of negative: 111821\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.750040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195585\n",
      "[LightGBM] [Info] Number of data points in the train set: 124480, number of used features: 767\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Лучшие параметры для модели LGBMClassifier с использованием кросс-валидации: {'n_estimators': 25, 'max_depth': 740, 'learning_rate': 0.25}\n",
      "Наибольшее значение метрики F1 для модели LGBMClassifier при лучших гиперпараметрах с использованием кросс-валидации: 0.9301937424319675\n",
      "CPU times: total: 46.4 s\n",
      "Wall time: 20min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(class_weight= 'balanced', random_state=12345) #\n",
    "parameters = {'n_estimators': estimators_range, 'max_depth': max_depth_range, 'learning_rate': np.arange(0.05, 0.5, 0.05)}\n",
    "#применение метода гридсёрч со встроенной кросс-валидацией\n",
    "\n",
    "rand_lgbm = RandomizedSearchCV(lgbm, n_iter=20, param_distributions= parameters, scoring='f1', n_jobs= -1, cv=5, random_state=12345)\n",
    "#обучение модели\n",
    "rand_lgbm.fit(features_train, target_train.values)\n",
    "\n",
    "#лучшее значение после перебора параметров \n",
    "best_lgbm = rand_lgbm.best_score_\n",
    "\n",
    "print(\"Лучшие параметры для модели LGBMClassifier с \"\\\n",
    "    \"использованием кросс-валидации:\", rand_lgbm.best_params_)\n",
    "print(\"Наибольшее значение метрики F1 для модели LGBMClassifier \"\\\n",
    "    \"при лучших гиперпараметрах с использованием кросс-валидации:\", best_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели LGBMClassifier лучшие параметры {'n_estimators': 25, 'max_depth': 740, 'learning_rate': 0.25}\n",
    "F1 : 0.930 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты работы моделей представлены ниже.\n",
    "- Лучшие параметры у модели RandomForestClassifier(class_weight='balanced', max_depth=400, n_estimators=21, random_state=12345). Лучший результат f1=0.939\n",
    "- Модель CatBoost показывает лучший результат в 'F1': 0.974\n",
    "- Для модели LGBMClassifier лучшие параметры {'n_estimators': 25, 'max_depth': 740, 'learning_rate': 0.25}. F1 : 0.930 \n",
    "\n",
    "Исходя из этого, наилучшей моделью для предсказания токсичности является CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9406940063091482\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 680 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Тестируем модель CatBoostRegressor\n",
    "pred_cat_test = cb.predict(features_test)\n",
    "print(f'F1:', f1_score(target_test, pred_cat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке результат позитивный. F1: 0.941.\n",
    "Метрика выше 0,75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- проведен анализ датасета. Выявлен дисбаланс. Около 10% токсичных комментариев, 90% не токсичны;\n",
    "- загрузили модель и токенизатор BERT;\n",
    "- проводим первичную токенизацию для текста. Выявили ограничение длины в 512 токенов. Очистили датасет от длинных комментариев.\n",
    "- создали эмбеддинги на выборке в 15900 строк\n",
    "- разбили выборку на тренировочныую и тестовую\n",
    "- обучили модели. Результаты работы моделей представлены ниже.\n",
    "  - Лучшие параметры у модели RandomForestClassifier(class_weight='balanced', max_depth=400, n_estimators=21, random_state=12345). Лучший результат f1=0.939\n",
    "  - Модель CatBoost показывает лучший результат в 'F1': 0.974\n",
    "  - Для модели LGBMClassifier лучшие параметры {'n_estimators': 25, 'max_depth': 740, 'learning_rate': 0.25}. F1 : 0.930\n",
    "\n",
    "    Исходя из этого, наилучшей моделью для предсказания токсичности является CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
